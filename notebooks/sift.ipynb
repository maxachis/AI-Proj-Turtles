{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in csv files.\n",
    "train = pd.read_csv('../train.csv')\n",
    "test = pd.read_csv('../test.csv')\n",
    "\n",
    "# get paths for all images\n",
    "turtle_imgs_dir = \"../image_datasets/turtle_origcrop\"\n",
    "train_image_paths = [os.path.join(turtle_imgs_dir, \"%s.JPG\" % f) for f in train.image_id]\n",
    "\n",
    "# load in all images in training set\n",
    "train_images = [cv2.imread(f, cv2.IMREAD_GRAYSCALE) for f in train_image_paths]\n",
    "\n",
    "# run SIFT to get all keypoints and descriptors in training set\n",
    "sift = cv2.xfeatures2d.SIFT_create(edgeThreshold=5, sigma=1.5, contrastThreshold=0.03, nOctaveLayers=1)\n",
    "keypoints, descriptors = zip(*[sift.detectAndCompute(image, None) for image in train_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matches(a, b):\n",
    "    des1 = descriptors[a]\n",
    "    des2 = descriptors[b]\n",
    "    key1 = keypoints[a]\n",
    "    key2 = keypoints[b]\n",
    "\n",
    "    bf = cv2.BFMatcher() # brute force image matcher\n",
    "\n",
    "    # get all keypoint matches\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "    matches2 = bf.knnMatch(des2, des1, k=2)\n",
    "\n",
    "    good = [[m] for (m,n) in matches if m.distance < 0.8 * n.distance]\n",
    "    good2 = [[m] for (m,n) in matches2 if m.distance < 0.8 * n.distance]\n",
    "    bimatches = [m1 for m1 in good for m2 in good2 if (m1[0].queryIdx == m2[0].trainIdx) and (m1[0].trainIdx == m2[0].queryIdx)]\n",
    "\n",
    "    # Filter the matches by removing outlier matches.\n",
    "    if len(bimatches) < 4: # minimum required to find_homography\n",
    "        return []\n",
    "\n",
    "    src_pts = np.float32([key1[m[0].queryIdx].pt for m in bimatches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([key2[m[0].trainIdx].pt for m in bimatches]).reshape(-1, 1, 2)\n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,ransacReprojThreshold=7.0)\n",
    "    matchesMask = mask.ravel().tolist()\n",
    "    filtered_matches = [i for i,j in zip(bimatches, matchesMask) if j == 1]\n",
    "\n",
    "    return filtered_matches\n",
    "\n",
    "\n",
    "def match_all_turtles(t_idx):\n",
    "    \"\"\" match this turtle id t_idx to all other turtle images and score them by the number of keypoint maches found\"\"\"\n",
    "    \n",
    "    all_idx = list(range(len(keypoints)))\n",
    "    all_idx.remove(t_idx)\n",
    "    scores = [(len(find_matches(t_idx, i)), i) for i in all_idx]\n",
    "    scores.sort()\n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "def generate_img(a, b):\n",
    "    matches = find_matches(a, b)\n",
    "    return cv2.drawMatchesKnn(train_images[a], keypoints[a], train_images[b], keypoints[b], matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "def output_top4(t_idx):\n",
    "    \"\"\"match all turtles to this id, sort by score, take the top 4 matches and plot them.\"\"\"\n",
    "    scores = match_all_turtles(t_idx)\n",
    "    scores.sort(reverse=True, key=lambda x: x[0])\n",
    "    top4 = scores[0:4]\n",
    "    fig, axes = plt.subplots(2,2, figsize=(16, 8), tight_layout=True)\n",
    "    for i, (score, b_idx) in enumerate(top4):\n",
    "        # print(train.turtle_id[t_idx], train.turtle_id[b_idx])\n",
    "        ax_idx = (i // 2, i % 2)\n",
    "        im = axes[ax_idx].imshow(generate_img(t_idx, b_idx))\n",
    "        axes[ax_idx].set_axis_off()\n",
    "        axes[ax_idx].set_title(\"LEFT %s (%d)/ RIGHT %s (%d): score=%d\" % (train.turtle_id[t_idx], t_idx, train.turtle_id[b_idx], b_idx, score))\n",
    "    # fig.show()\n",
    "    fig.savefig(\"%s.png\" % train.turtle_id[t_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOOD example 1\n",
    "output_top4(t_idx=2028)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SURPRISINGLY GOOD match1\n",
    "output_top4(t_idx=903)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SURPRISINGLY GOOD match 2\n",
    "output_top4(t_idx=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad match 1\n",
    "output_top4(t_idx=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad match 2\n",
    "output_top4(t_idx=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_top4(t_idx=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_top4(t_idx=)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fdb13ca680928c35a3ab18084a9fa02308e46b0f92af8d0077455b0ca8584e77"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('3.10.0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
